library(rtweet)
library(quanteda)
library(lubridate)
library(topicmodels)
library(ggplot2)

analysis<- search_tweets("#stayhomesavelives",n=40000,lang="en")

corpusve<- corpus(analysis)
tweets<- dfm(analysis$text,
    remove_punct = TRUE, remove_url = TRUE, remove_symbols = TRUE,
    remove = c('*.tt', '*.uk', '*.com', 'rt', '#*', '@*', 'http*', 'amp')) %>%   ## here you can also add other words you can think of
  dfm_remove(stopwords('en')) ## this depends on the language you are searching in (i.e. it is italian; es is spanish and so on. check the ISO attached to package)

head(tweets)

## transforming the file in quanteda-readable format making matrix (preparing for network analysis)

tag_dfm <- dfm_select(tweets)
head(tag_dfm)
tweets_fcm <-fcm(tag_dfm)

##searching most used hashtags in corpus. You can skip this if not interested!

toptag <- names(topfeatures(tag_dfm, 50))
head(toptag)   ##list of most used hashtags
 
# OR network of tags

tag_fcm<- fcm(tag_dfm)
toptag<-names(topfeatures(tag_dfm,50))
topgat_fcm<- fcm_select(tag_fcm,pattern=toptag)
textplot_network(topgat_fcm, min_freq = 0.1, edge_alpha = 0.8, edge_size = 5)

# OR Network of tweets (words) made by tokenising the text

toks<- corpusve %>%
  + tokens(remove_punct = TRUE) %>%
  + tokens_remove(stopwords("english"), padding = FALSE)
  
fcmat <- fcm(tweets, context = "window", tri = FALSE)
feat <- names(topfeatures(fcmat, 30))
fcm_select(fcmat, pattern = feat) %>%
  +     textplot_network(min_freq = 0.5)
  
  
## OR Network of tweets by date
analysis %>%
  ts.plot("databyday") +
  ggplot2::theme_minimal() +
  ggplot2::theme(plot.title = ggplot2::element_text(face = "bold")) +
  ggplot2::labs(
    x = NULL, y = NULL,
    title = "Frequency of tweets from-to"
    )                         ## to add subtitles add subtitle="subtitle"
    
    

##this code has been created for training purposes. more information about the package can be found at: https://quanteda.io
